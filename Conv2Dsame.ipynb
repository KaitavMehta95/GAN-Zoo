{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Conv2dSame(nn.Module):\n",
    "    \"\"\" Applies a 2D convolution  over an input signal composed of several input\n",
    "        planes and output size is the same as input size.\n",
    "        Args:\n",
    "            in_channels (int): Number of channels in the input image\n",
    "            out_channels (int): Number of channels produced by the convolution\n",
    "            kernel_size (only tuple): Size of the convolving kernel\n",
    "            stride (only int): Stride of the convolution. Default: 1\n",
    "            padding_layer: type of layer for padding. Default: nn.ZeroPad2d\n",
    "            dilation (only int): Spacing between kernel elements. Default: 1\n",
    "            bias (bool): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
    "\n",
    "        Shape:\n",
    "            - Input: :math:`(N, C_{in}, H_{in}, W_{in})`\n",
    "            - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding_layer=nn.ZeroPad2d, dilation=1, bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        kernel_h, kernel_w = kernel_size\n",
    "\n",
    "        k = dilation * (kernel_w - 1) - stride + 2\n",
    "        pr = k // 2\n",
    "        pl = pr - 1 if k % 2 == 0 else pr\n",
    "\n",
    "        k = dilation * (kernel_h - 1) - stride + 1 + 1\n",
    "        pb = k // 2\n",
    "        pt = pb - 1 if k % 2 == 0 else pb\n",
    "        self.pad_same = padding_layer((pl, pr, pb, pt))\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                              stride, dilation=dilation, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pad_same(x)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 16, 16])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Conv2dSame(1,64,(4,4),1)  #64\n",
    "\n",
    "c1 = Conv2dSame(64,100,(4,4),1)  #64\n",
    "\n",
    "h = nn.Conv2d(100,127,4,2,1) #32\n",
    "\n",
    "c2 = Conv2dSame(127,512,(4,4),1) #32\n",
    "\n",
    "h2 = nn.Conv2d(512,1,4,2,1) #16\n",
    "\n",
    "y = h2(c2(h(c1(c(torch.rand((64,1,64,64))))))) #16\n",
    "\n",
    "\n",
    "y.shape\n",
    "\n",
    "# c2(c(torch.rand((64,1,64,64)))).shape\n",
    "# c3 = Conv2dSame(127,387,(4,4),1)\n",
    "# y = c3(c2(c(torch.rand((64,1,64,64)))))\n",
    "\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "\n",
    "class Conv2dSame(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1):\n",
    "        super(Conv2dSame, self).__init__()\n",
    "        self.F = kernel_size\n",
    "        self.S = stride\n",
    "        self.D = dilation\n",
    "        self.layer = nn.Conv2d(in_channels, out_channels, kernel_size, stride, dilation=dilation)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        N, C, H, W = x_in.shape\n",
    "        H2 = math.ceil(H / self.S)\n",
    "        W2 = math.ceil(W / self.S)\n",
    "        Pr = (H2 - 1) * self.S + (self.F - 1) * self.D + 1 - H\n",
    "        Pc = (W2 - 1) * self.S + (self.F - 1) * self.D + 1 - W\n",
    "        x_pad = nn.ZeroPad2d((Pr//2, Pr - Pr//2, Pc//2, Pc - Pc//2))(x_in)\n",
    "        x_out = self.layer(x_pad)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.shape\n",
    "\n",
    "b = Conv2dSame(1,64,4,1)\n",
    "print(b(torch.rand((64,1,64,64))).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "\n",
    "ngpu =1\n",
    "noDlayers = 10\n",
    "activationF = [randint(0, 3) for x in range(noDlayers-1)]\n",
    "opChannels = [randint(64, 513) for i in range(noDlayers-1)]\n",
    "same_conv2d_pos = {5: [0, 0, 0, 0, 0],\n",
    "                       6: [0, 1, 0, 0, 0, 0],\n",
    "                       7: [0, 1, 0, 1, 0, 0, 0],\n",
    "                       8: [0, 1, 0, 1, 0, 1, 0, 0],\n",
    "                       9: [0, 1, 0, 1, 0, 1, 0, 1, 0],\n",
    "                       10: [0, 1, 1, 0, 1, 0, 1, 0, 1, 0]}\n",
    "nc =1\n",
    "ndf =64\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu, opChannels, activationF,same_conv2d_pos):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.activationF = activationF\n",
    "        self.opChannels = opChannels\n",
    "\n",
    "\n",
    "        ip = nc\n",
    "        op = ndf\n",
    "        i = 0\n",
    "        model = []\n",
    "#         op = self.opChannels[i]\n",
    "        while i < noDlayers-1:\n",
    "            \n",
    "            if same_conv2d_pos[noDlayers][i] == 1:\n",
    "                # Add a 6th same padding layer !\n",
    "                model += [Conv2dSame(ip, op, (4, 4), 1)]\n",
    "            else:\n",
    "                model += [nn.Conv2d(ip, op, 4, 2, 1)]\n",
    "            \n",
    "            if i > 0:\n",
    "                model += [nn.BatchNorm2d(op)]\n",
    "\n",
    "            if self.activationF[i] == 0:\n",
    "                model += [nn.LeakyReLU(0.2)]\n",
    "            elif self.activationF[i] == 1:\n",
    "                model += [nn.ReLU(inplace=True)]\n",
    "            elif self.activationF[i] == 2:\n",
    "                model += [nn.ELU(inplace=True)]\n",
    "\n",
    "\n",
    "            ip = op\n",
    "            op = self.opChannels[i]\n",
    "\n",
    "            i = i+1\n",
    "        model += [\n",
    "            nn.Conv2d(ip, 1, 4, 1),\n",
    "            nn.Sigmoid()]\n",
    "        self.main = torch.nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "    \n",
    "\n",
    "    \n",
    "netD = Discriminator(1,opChannels,activationF,same_conv2d_pos).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2dSame(\n",
       "      (pad_same): ZeroPad2d(padding=(1, 2, 2, 1), value=0.0)\n",
       "      (conv): Conv2d(64, 331, kernel_size=(4, 4), stride=(1, 1))\n",
       "    )\n",
       "    (3): BatchNorm2d(331, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Conv2dSame(\n",
       "      (pad_same): ZeroPad2d(padding=(1, 2, 2, 1), value=0.0)\n",
       "      (conv): Conv2d(331, 226, kernel_size=(4, 4), stride=(1, 1))\n",
       "    )\n",
       "    (6): BatchNorm2d(226, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): ELU(alpha=1.0, inplace)\n",
       "    (8): Conv2d(226, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace)\n",
       "    (11): Conv2dSame(\n",
       "      (pad_same): ZeroPad2d(padding=(1, 2, 2, 1), value=0.0)\n",
       "      (conv): Conv2d(64, 233, kernel_size=(4, 4), stride=(1, 1))\n",
       "    )\n",
       "    (12): BatchNorm2d(233, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ELU(alpha=1.0, inplace)\n",
       "    (14): Conv2d(233, 492, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (15): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): LeakyReLU(negative_slope=0.2)\n",
       "    (17): Conv2dSame(\n",
       "      (pad_same): ZeroPad2d(padding=(1, 2, 2, 1), value=0.0)\n",
       "      (conv): Conv2d(492, 462, kernel_size=(4, 4), stride=(1, 1))\n",
       "    )\n",
       "    (18): BatchNorm2d(462, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace)\n",
       "    (20): Conv2d(462, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (21): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace)\n",
       "    (23): Conv2dSame(\n",
       "      (pad_same): ZeroPad2d(padding=(1, 2, 2, 1), value=0.0)\n",
       "      (conv): Conv2d(128, 250, kernel_size=(4, 4), stride=(1, 1))\n",
       "    )\n",
       "    (24): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(250, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (27): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "dataroot = \"C:/Users/RACHIT/Desktop/coegan-master/mnist_png/training\"\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.Grayscale(1),\n",
    "                                   transforms.Resize(64),\n",
    "                                   transforms.CenterCrop(64),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               ]))\n",
    "# Create the dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64,\n",
    "                                             shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if hasattr(m, 'weight') and classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "netD.zero_grad()\n",
    "data = next(iter(dataloader))\n",
    "real_cpu = data[0].to(device)\n",
    "print(real_cpu.shape)\n",
    "\n",
    "netD.apply(weights_init)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "output = netD(real_cpu)\n",
    "print(output.shape)\n",
    "# output .view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(output.view(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
